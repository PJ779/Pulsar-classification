# -*- coding: utf-8 -*-
"""HTRU2 Final code?.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u2TrpcrpzjjmVW3Ok2Aloax2_Nm1-duf
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.cluster import DBSCAN
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

from sklearn.neighbors import KNeighborsClassifier
from imblearn.pipeline import Pipeline
from sklearn.decomposition import FastICA
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import layers, models
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score

data = pd.read_csv('HTRU_2.csv', sep=',',header=None)
data

data.shape

column=['Mean_integrated_profile',
       'standard_dev_integrated_profile',
       'Excess_kurtosis_integrated_profile',
       'Skew_integrated_profile', 'Mean_DM_SNR',
       'standard_dev_DM_SNR',
       'Excess_kurtosis_DM_SNR', 'Skew_DM_SNR',
       'class']
data.columns = column

print(data['class'].unique())

data.info()

data.head(5)

data.isnull().any()

data.describe().T

correlation = data.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation, annot=True)
plt.title('Correlation Heatmap of Pulsar candidates collected during the High Time Resolution Universe survey')
plt.show()

no_outcome = data.drop('class', axis= 1)
HTRU_hist = no_outcome.hist(figsize=(8,8), grid = False, bins = 10)

data_copy = data.copy(deep = True)

plt.figure(figsize=(6, 6))
plots = sns.PairGrid(data_copy, hue='class')
plots.map_offdiag(sns.scatterplot)
plots.map_diag(sns.histplot)

target = data_copy.pop('class')
target.value_counts()
#imbalance so using SMOTE

X_train = no_outcome.astype(np.float32)

pipeline = Pipeline([
    ('scaler', MinMaxScaler()),
    ('pca', PCA()),
    ('smote', SMOTE(sampling_strategy=0.5)),
    ('classifier', KNeighborsClassifier(n_neighbors=3))  # You can replace this with your desired classifier
])

X_train, X_test, y_train, y_test = train_test_split(X_train, target, test_size=0.2, random_state=42)

pipeline.fit(X_train, y_train)

X_train_resampled, y_train_resampled = pipeline.named_steps['smote'].fit_resample(pipeline.named_steps['pca'].transform(pipeline.named_steps['scaler'].transform(X_train)), y_train)
print("Shape of X_train_resampled:", X_train_resampled.shape)
print("Shape of y_train_resampled:", y_train_resampled.shape)

pca = PCA()
pca_result_full = pca.fit(X_train)


explained_variance_ratio = pca.explained_variance_ratio_

# Plot the scree plot
plt.figure(figsize=(10, 6))
plt.plot(np.cumsum(explained_variance_ratio), marker='o', linestyle='-', color='r')
plt.title("Explained variance as a function of the number of dimensions:")
plt.xlabel('Number of features')
plt.ylabel('Explained Variance')
plt.show()

pca = PCA(n_components=0.95) # we can try using svd_solver="randomized"
scaled_pca_X = pca.fit_transform(X_train)

pca.n_components_

#X_train, X_test, y_train, y_test = train_test_split(scaled_pca, target, test_size=0.2, random_state=42)

#smote = SMOTE(sampling_strategy=0.5)  # Adjust the sampling strategy as needed
#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
#print("Shape of X_train_resampled:", X_train_resampled.shape)
#print("Shape of y_train_resampled:", y_train_resampled.shape)

"""Since the outcome is binary, I will attempt to utilize

logistic regression
SVM
Random Forest Classifier
Neural Networking
"""

param_grid = {
    'n_estimators': [100, 200, 300],    # Try different values for the number of trees
    'max_depth': [5, 7, 10],           # Try different values for the maximum depth of trees
}

X = X_train_resampled
y = y_train_resampled
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state = 12)
rf = RandomForestClassifier(n_estimators=100, random_state = 2, max_depth=5)
rf.fit(X_train, Y_train)
print('Training score: {}'.format(rf.score(X_train, Y_train)))
print('Test score: {}'.format(rf.score(X_test, Y_test)))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score


# Define a grid of hyperparameters to search
param_grid = {
    'n_estimators': [50, 100, 200],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create a Random Forest Classifier
rf_classifier = RandomForestClassifier(random_state=42)

# Create a GridSearchCV object
grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Perform the grid search
grid_search.fit(X_train, Y_train)

#Get the best parameters
best_params = grid_search.best_params_

# Train the model with the best hyperparameters
best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)
best_rf_classifier.fit(X_train, Y_train)

# Make predictions on the test data
y_pred = best_rf_classifier.predict(X_test)

# Calculate the accuracy of the model
rf_acc = accuracy_score(Y_test, y_pred)
print("Best Parameters:", best_params)
print("Accuracy:", rf_acc)

from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.tree import export_graphviz

def predict_and_plot(model, input, target, name=''):
    prediction = model.predict(input)
    accuracy = accuracy_score(target, prediction)


    cf = confusion_matrix(target, prediction, normalize='true')
    plt.figure()
    sns.heatmap(cf, annot=True)
    plt.xlabel('Prediction')
    plt.ylabel('Target')
    plt.title('{} Confusion Matrix'.format(name))

    return prediction

#plotting the data
train_prediction = predict_and_plot(rf, X_train, Y_train, 'Train')

# plotting the data
test_prediction = predict_and_plot(rf, X_test, Y_test, 'Test')

#KNN
knn = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors (k)

# Train the classifier on the training data
knn.fit(X_train, Y_train)

# Make predictions on the test data
y_pred = knn.predict(X_test)

# Evaluate the performance of the classifier
knn_acc = accuracy_score(Y_test, y_pred)
print("Accuracy:", knn_acc)

# Print a classification report for more detailed evaluation metrics
print("Classification Report:")
print(classification_report(Y_test, y_pred))

from matplotlib.colors import ListedColormap

def plot_decision_boundary(X, y, model, title):
    h = .02  # step size in the mesh
    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])
    cmap_bold = ListedColormap(['#FF0000', '#0000FF'])

    # Plot the decision boundary. For that, we will assign a color to each point in the mesh [x_min, x_max]x[y_min, y_max].
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    # Plot also the training points
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.title(title)
    plt.show()

# Assuming X_train is a 2D array with two features for visualization
X_train_2d = X_train[:, :2]
knn.fit(X_train_2d, Y_train)

# Visualize the decision boundary for KNN
plot_decision_boundary(X_train_2d, Y_train, knn, 'KNN Decision Boundary')

param_grid = {
    'C': [0.1, 1, 10, 100],          # Regularization parameter
    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient
    'kernel': ['linear', 'rbf']     # Kernel type
}

#SVM
svm_classifier = SVC()

grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

grid_search.fit(X_train_resampled, y_train_resampled)

best_params = grid_search.best_params_

best_svm_classifier = SVC(**best_params)
best_svm_classifier.fit(X_train_resampled, y_train_resampled)

print("Shape of X_train_resampled:", X_train_resampled.shape)
print("Shape of y_train_resampled:", y_train_resampled.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_test:", Y_test.shape)

y_pred = best_svm_classifier.predict(X_test)
svm_acc = accuracy_score(Y_test, y_pred)
print("Best Parameters:", best_params)
print("Accuracy:", svm_acc)

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, Y_train, epochs=50, batch_size=100, validation_split=0.2, verbose=2)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

# Assuming you have a dataset with features (X) and labels (y)
# Split your data into training and testing sets

# Encode labels if they are not numeric

label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(Y_train)

# Define the TransformerEncoder class
class TransformerEncoder(layers.Layer):
    def __init__(self, num_heads, ff_dim, dropout_rate=0.1, **kwargs):
        super(TransformerEncoder, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.dropout_rate = dropout_rate
        self.att = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.ff_dim)
        self.ffn = tf.keras.Sequential(
            [layers.Dense(self.ff_dim, activation="relu"), layers.Dense(self.ff_dim)]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(self.dropout_rate)
        self.dropout2 = layers.Dropout(self.dropout_rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

# Define the TransformerClassifier class
class TransformerClassifier(models.Model):
    def __init__(self, num_heads, ff_dim, num_classes, input_dim, dropout_rate=0.1, **kwargs):
        super(TransformerClassifier, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.num_classes = num_classes
        self.input_dim = input_dim
        self.dropout_rate = dropout_rate
        self.embedding = layers.Embedding(self.input_dim, self.ff_dim)
        self.transformer_block = TransformerEncoder(self.num_heads, self.ff_dim, self.dropout_rate)
        self.global_avg_pooling = layers.GlobalAveragePooling1D()
        self.dense = layers.Dense(self.num_classes, activation='softmax')

    def call(self, inputs, training):
        x = self.embedding(inputs)
        x = self.transformer_block(x, training=training)
        x = self.global_avg_pooling(x)
        return self.dense(x)

# Function to create a model
def create_model(num_heads=2, ff_dim=32, dropout_rate=0.1):
    model = TransformerClassifier(
        num_heads=num_heads,
        ff_dim=ff_dim,
        num_classes=len(label_encoder.classes_),
        input_dim=X_train.shape[1],
        dropout_rate=dropout_rate
    )
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Create a KerasClassifier for compatibility with GridSearchCV
keras_clf = KerasClassifier(build_fn=create_model, epochs=5, batch_size=32, verbose=0)

# Define the hyperparameters to tune
param_grid = {
    'num_heads': [2, 4, 6],
    'ff_dim': [32, 64, 100],
    'dropout_rate': [0.1, 0.2, 0.25]
}

# Create GridSearchCV
grid_search = GridSearchCV(estimator=keras_clf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)

# Fit the grid search to the data
grid_result = grid_search.fit(X_train, y_train_encoded)

# Summarize the results
print(f"Best Accuracy: {grid_result.best_score_:.4f} using {grid_result.best_params_}")

# Retrieve the best model
best_model = grid_result.best_estimator_.model
best_model.summary()

# Evaluate the best model on the test set
test_loss, test_acc = best_model.evaluate(X_test, label_encoder.transform(Y_test), verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

def plot_training_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))

    # Plot training and validation accuracy
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'b', label='Training acc')
    plt.plot(epochs, val_acc, 'r', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot training and validation loss
    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'b', label='Training loss')
    plt.plot(epochs, val_loss, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

history = best_model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test, label_encoder.transform(Y_test)))

plot_training_history(history)

from xgboost import XGBClassifier

xgb = XGBClassifier(use_label_encoder =False)

xgb.fit(X_train, Y_train)
xgb

y_pred = xgb.predict(X_test)

xgb_acc = accuracy_score(Y_test, y_pred)
print("XGBoost Accuracy:", xgb_acc)

model_names = ['Random Forest', 'KNN', 'SVM', 'XGBoost']
accuracy_scores = [rf_acc, knn_acc, svm_acc, xgb_acc]  # Replace with your actual accuracy scores

# Create a bar plot
plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'orange', 'purple'])
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Comparison')
plt.ylim(0, 1)  # Set y-axis limits to the range of accuracy scores (0 to 1)
plt.show()